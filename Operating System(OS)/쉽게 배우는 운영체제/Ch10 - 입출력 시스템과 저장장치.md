# **Chapter10 - 입출력 시스템과 저장장치**

# **[ 📋 목차 ]**
- 입출력 시스템
- 디스크 장치
- 디스크 스케줄링
- RAID
- 하드웨어의 규격과 발전

****

# **[ 🗂️ 정리 ]**
## 📌 <b>입출력 시스템</b>

### ⚙ <b>입출력장치와 채널</b>
컴퓨터는 필수장치인 CPU 와 메모리, 입출력장치와 저장장치로 구성된다.  
각 저장장치는 메인보드에 있는 버스로 연결된다.  
주변장치는 데이터 전송 속도에 따라 저속 주변장치와 고속 주변장치로 구분된다.

- 저속 주변장치: 메모리와 주변장치 사이에 오고 가는 데이터의 양이 적어 데이터 전송률이 낮은 장치
- 고속 주변장치: 메모리와 주변장치 사이에 대용량의 데이터가 오고가서 전송률이 높은 장치

한 개의 버스만 사용하면 병목 현상이 발생할 수 있기 때문에 여러개의 버스를 묶어서 사용하고, 데이터가 지나다니는 하나의 통로를 '채널' 이라고 한다.  
채널마다 전송량이 다르기 때문에 속도가 비슷한 장치끼리 묶어서 사용하는게 좋다.

### ⚙ <b>입출력 버스의 구조</b>
많은 주변장치의 등장으로 초기에는 문제 없었던 폴링(Polling) 방식으로 주변장치 관리가 어려워져서 모든 입출력을 입출력 제어기(I/O Controller) 에 맡기는
구조로 바뀌었다.

[그림10-4] p.427

입출력 제어기는 메인버스와 입출력 버스 두 개의 버스로 나뇐다.  
입출력 장치들중에서는 그래픽카드 같은 고속 주변장치가 있는 반면에 키보드, 마우스같은 저속 주변장치도 있기 때문에 하나의 입출력 버스를 공유하는건 성능의 저하로
이어질 수 밖에 없다.

[그림10-5] p.428

따라서 입출력 버스를 고속과 저속으로 나눌 필요가 있고, 그 사이를 관리하는게 채널 선택기(Channel Selector) 이다.  
그래픽 카드의 경우 GPU 를 부착하고, CPU 를 능가할 계산 능력을 갖고있기 때문에 입출력 버스로 감당할 수 없을 대용량 전송량을 갖고 있어서 메인 버스로 분리해서
사용한다.

### ⚙ <b>직접 메모리 접근</b>

메모리는 CPU 의 명령에 따라서 작동하지만 직접 메모리 접근(Direct Memory Access) 를 통해서 CPU 의 도움 없이 메모리에 접근할 수 있다.
 
[그림 10-6] p.474

그림을 보면 입출력 제어기가 여러 채널에서 받은 데이터를 하나의 데이터 흐름으로 만들어 어느 데이터를 메모리에 보낼지 결정하고, DMA 를 거쳐서 메모리에 
데이터가 적재되게 되고, 반대 방향의 경우 DMA 를 통해서 데이터를 가져와 채널 선택기를 통해서 적당한 채널로 전송한다.  
  
메인메모리는 CPU 가 작업하는 공간인데, DMA 랑 CPU 가 데이터를 가져오거나, 가져가는 작업 공간이 겹치게 된다.

[그림 10-7] p.474

과거에는 (a) 처럼 DMA 를 통해 가져온 데이터를 별도의 저장공간에 가져왔으나 이 방식은 메모리에서 입출력 메모리로 옮기는 불필요한 작업이기 때문에 (b) 처럼
메모리 상에서 작업하는 공간이 분리되어 운영되고, 이를 메모리 맵 입출력(Memory Mapped I/O) 라고 부른다.

### ⚙ <b>인터럽트</b>

#### 👉 입출력과 인터럽트
입출력 제어기와 DMA 제어기의 작업이 완료되면 CPU 에 인터럽트를 발생 시킨다.  
다양한 장치가 있기 때문에 장치를 식별하기 위해서 각 장치는 IRQ(Interrupt Request) 라는 고유의 인터럽트 번호가 부여되어 있다.

- 외부 인터럽트: 키보드, 마우스 같은 입출력 장치로부터 오는 인터럽트(= Hardware Interrupt)
- 내부 인터럽트: 0으로 나누기 등 프로세스의 오류와 관련된 인터럽트(= Exception)
- 시그널: 사용자가 직접 발생 시키는 인터럽트 ex) kill

#### 👉 인터럽트 벡터와 인터럽트 핸들러
'인터럽트 벡터' 는 어느 인터럽트가 발생했는지 파악하기 위한 자료구조로 벡터의 값이 1이면 발생 했다는 뜻이다.  
인터럽트 벡터에는 인터럽트를 처리할 수 있는 인터럽트 핸들러 함수를 호출할 수 있도록 핸들러가 저장된 메모리 주소를 포인터로 가지고 있다.

### ⚙ <b>버퍼링</b>

#### 👉 버퍼의 역할
속도가 다른 두 장치의 속도 차이를 완화하는 역할을 한다.

## 📌 <b>디스크 장치</b>

### ⚙ <b>디스크 장치의 종류</b>

#### 👉 하드디스크(Hard Disk Driver, HDD)
초기 테이프 드라이브는 순차적으로 접근해야해서 맨 뒤에 있는 데이터를 접근하기 위해서 테이프를 끝까지 감았어야 했는데, 원반 형태의 하드디스크는 
앞, 뒤 접근 속도가 비슷해서 도입되었다.

[그림10-12] p.482
  
스핀들(Spindle) 이라는 원통 축에 여러개의 플래터(Platter) 기 달려있다.

- 플래터
    - 표면에 자성체가 발려 있어 자기를 이용해 0과 1의 데이터를 저장한다.
        - N극 0, S극 1
    - 2장 이상의 구성에, 일정한 속도로 회전한다.
    - 위, 아래 표면을 다 사용하여 2개의 표면에 데이터 저장한다.
- 섹터와 블록(Sector & Block)
    - 섹터는 하드디스크의 가장 작은 저장 단위이다.
    - 블록은 하드디스크와 컴퓨터 사이의 데이터를 전송하는 논리적인 저장 단위 중 가장 작은 단위이다.
        - 여러개의 섹터로 구성된다.
    - 하드디스크에서는 섹터가 가장 작은 단위이고, 운영체제에서는 블록이 가장 작은 단위이다.
- 트랙과 실린더(Track & Cylinder)
    - 트랙은 동심원상에 있는 섹터의 집합을 말한다. (원형 트랙 생각하면 편함)
    - 헤드는 디스크 암(Disk Arm) 에 고정되어 있어 모든 헤드가 항상 같이 움직인다.
        - 모든 헤드는 항상 같은 위치의 플래터의 트랙을 동시에 읽거나 쓸 수 있다.
    - 여러개의 플래터에 있는 같은 트랙들의 집합을 실런더라 한다.
- 헤드와 플래터
    - 하드디스크에서 데이터를 읽거나 쓸 때 읽기/쓰기 헤드(read/write head) 를 사용한다.
    - 헤드의 수는 저장되는 플래터의 표면의 수와 같다.
    - 회저시 헤드가 플래터에 붙어 고속으로 회전하는 플래터에 상처를 입히면 데이터를 저장할 수 없는 배드 섹터(Bad Sector)가 된다.
    - 컴퓨터 종료시 헤드를 데이터가 저장되지 않는 플래터 밖으로 이동하는데 이를 파킹(Parking) 이라고 한다. (컴퓨터 전원을 뽑거나 정전시 배드 섹터가 만들어 질 수
      있기 때문에 정상 종료가 가장 좋다.)
    
[그림10 - 13] p.483

#### 👉 CD(Compact Disc)
하드디스크처럼 원반을 사용하는 저장장치로 휴대할 수 있는 소형 원반에 데이터를 저장한다.  
하드디스크와 같이 트랙과 섹터로 구성되며, 수평으로 움직이는 헤드가 트랙 사이를 움직이면서 데이터를 읽는다.
  
[그림10-14] p.484

파인 홈에 헤드에서 발사된 레이저가 홈에 들어가 반사되지 않으면 0, 반사되면 1로 인식한다.

### ⚙ <b>디스크 장치 관리</b>

#### 👉 파티션(Partition)
디스크를 논리적으로 분할하는 작업이다.  

[그림 10-18] p.489

- (a): 2개의 하드디스크를 사용해 별도의 파일 시스템이 탑재된 2개의 하드디스크로 보인다.
- (b): 1개의 하드디스크를 사용해 2개의 파티션으로 나누어 각각의 파티션에 파일 시스템을 탑재
- (c): 여러개의 하드디스크가 하나의 파티션으로 보이도록 통합(마운트, Mount)

파티션을 나누면 C, D... 드라이브 처럼 나뉘지만, 100개, 200개가 넘어가면 AB 드라이브, AC 드라이브 처럼 관리하기 힘들어질 것이다.

#### 👉 포맷팅(Formatting)
디스크를 초기화 하는 작업이다.  
파티션이 결정된 후 파일 시스템을 탑재하고, 디스크 표면을 초기화 하여 사용할 수 있는 형태로 만드는 작업을 한다.
  
가상 메모리의 페이지 테이블과 같이 디스크도 저장된 파일의 위치와 크기 정보를 담고 있는 파일 테이블을 사용한다.  
빈 저장장치에 파일 테이블을 탑재하는 것이 포매팅이다.  

모든 섹터를 0으로 만드는 작업이 느린 포매팅이며, 빠른 포매팅은 데이터는 그대로 둔 채 파일 테이블만 초기화 하는 방식이다.  
배드 섹터를 찾고 싶다면 느린 포매팅을 이용하면 된다.

#### 👉 조각 모음(Disk Defragmentation)
파티션 나누고, 포맷팅 이 후 하드디스크 사용하다 보면 점점 느려지는 경우가 발생하는데, 하드디스크에 데이터가 앞에서부터 차곡차곡 쌓이다가 지우면서 중간에
빈 공간이 생기는 단편화가 발생한다.
  
단편화가 생긴 디스크에서 데이터를 저장할 때 나뉘어서 저장되고, 지역성 없게 저장되기 때문에 성능 저하로 이어진다.

### ⚙ <b>네트워크 저장장치</b>

네트워크에서 사용하는 저장장치는 어떻게 구성하느냐에 따라서 DAS, NAS, SAN 으로 나뉜다.

#### 👉 DAS(Direct Attached Storage)
HAS(Host Attached Storage) 라고도 불리며, 서버와 같은 컴퓨터에 직접 연결된 저장장치를 말한다.  
컴퓨터의 메인보드에 있는 입출력 버스와 연결된다.  

컴퓨터에 직접 연결된 저장장치를 사용하기 때문에 다른 운영체제가 쓰는 파일 시스템을 사용할 수 없다. (서버가 윈도우면 윈도우 파일 시스템만 사용할 수 있다.)

#### 👉 NAS(Network Attached Storage)
LAN 이나 WAN 에 붙여서 사용하는 방식이다.  

DAS 의 경우 각각의 컴퓨터에 붙어있기 때문에 공유 데이터 관리가 힘들고 데이터가 중복되는 단점이 있어, NAS 는 저장장치를 네트워크상에 두어 여러 클라이언트가
네트워크를 통해서 접근하게 함으로 공유 데이터를 관리한다.

#### 👉 SAN(Storage Area Network)
데이터 서버, 백업 서버, RAID 등의 장치를 네트워크로 묶고 사용하는 방법으로 NAS 의 진보된 형태이다.  
하지만 구축 비용이 크다.

## 📌 <b>디스크 스케줄링(Disk Scheduling)</b>
그림 없이 이해가 힘들만한 내용이어서 트랙에 접근하는 순서를 먼저 소개한다.  
트랙은 0 ~ 24까지 총 25트랙으로 구성되어 있다.

```
| 순번 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
| 트랙 | 15| 8 | 17| 11| 3 | 23| 19| 14| 20|
```

### ⚙ <b>First Come, First Service, FCFS</b>
요청이 들어온 트랙 순서대로 서비스 한다.  

[그림10-25] p.497

```
[ 트랙의 이동 거리 ]
7+9+6+8+20+4+5+6=65
```

### ⚙ <b>Shortest Seek Time First, SSTF</b>
현재 헤드의 위치에서 가장 가까운 트랙부터 서비스 한다.

[그림10-26] p.497

```
[ 트랙의 이동 거리 ]
1+3+3+1+3+12+3+5=31
```

FCFS 스케줄링에 비해서 절반 이상 줄어든 모습을 보이지만, 헤드가 중간에 위치할 때 가장 안쪽이나 바깥쪽에 있는 트랙이 서비스 받을 확률이 낮아져서
'아사' 현상이 일어날 수 있다.

### ⚙ <b>block SSTF</b>
공평성을 어느 정도 해결한 기법으로 스케줄링 큐에 있는 트랙을 일정한 블록으로 묶어서 서비스 한다.

```
      ↱  Block  ↰ ↱  Block  ↰ ↱  Block  ↰
| 순번 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
| 트랙 | 15| 8 | 17| 11| 3 | 23| 19| 14| 20|

위 처럼 블록으로 묶은 다음 트랙중에서 가까운 트랙 순으로 방문하도록 한다.

      ↱  Block  ↰ ↱  Block  ↰ ↱  Block  ↰
| 순번 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
| 트랙 | 15| 17| 8 | 11| 3 | 23| 20| 19| 14|
```

블록 내에서는 마지막에 실행되는 트랙이 가장 먼 트랙이기 때문에 몇 번의 실행으로 반대쪽 트랙도 서비스 받을 수 있는 조건이 마련된다.

[그림10-28] p.499

```
[ 트랙의 이동 거리 ]
2+9+3+8+20+3+1+5=51
```

### ⚙ <b>SCAN</b>
SSTF 의 공평성 위배 문제를 완화하기 위해 만들어진 기법으로 헤드가 한 방향으로만 움직이면서 서비스 한다.

[그림10-29] p.500

```
[ 트랙의 이동 거리 ]
1+3+3+5+3+17+2+1+3=38
```

공평하면서 성능이 좋은 편이나 동일한 트랙이나 실린더 요청이 계속해서 들어오면 '아사' 현상이 발생한다. 

### ⚙ <b>Circular-SCAN</b>
SCAN Disk Scheduling 도 공평하지 못한 알고리즘인데, 그 이유는 양쪽 사이드를 1번씩 방문하는동안 중간 지점을 2번 통과하기 때문에
사이드의 트랙이 상대적으로 불이익을 받는다.  
  
SCAN 스케줄링을 변형해서 한 쪽 방향에 도달하면 이동할 때 중간 지점을 거치는게 아니라 작업 없이 이동만 하는 방법이다.

[그림 10-30] p.501

```
[ 트랙의 이동 거리 ]
1+3+5+3+24+1+3+1+2=46
```

하지만 작업 없이 헤드를 이동만 하는건 비효율적이다.  
동일한 트랙에 대한 '아사' 현상은 여전히 남아있다.

### ⚙ <b>LOOK</b>
SCAN 스케줄링 방법에서 불필요한 부분을 제거하여 효율을 높인 기법이다.  
헤드가 마지막 지점에 도착한 후 방향을 바꾸는 방법에서 이제는 마지막 까지 가지 않고, 더 방문할 트랙이 없는 경우 방향을 바꾼다.

[그림 10-31] p.501

```
[ 트랙의 이동 거리 ]
1+3+3+5+17+2+1+3=35
```

SCAN 보다 성능이 향상된 개선된 방법이다.

### ⚙ <b>C-LOOK</b>
C-SCAN 에서 LOOK 버전을 도입한 방법이다.

[그림 10-32] p.502

```
[ 트랙의 이동 거리 ]
1+3+5+20+3+1+2=38
```

### ⚙ <b>Shortest Latency Time First, SLTF</b>
일부 하드디스크의 경우 헤드 지지대를 고정하고, 모든 트랙을 읽을 수 있는 여러 개의 헤드를 지지대에 부착한다.  
헤드를 움직이는 탐색 시간이 없어 매우 빠르게 데이터를 주고 받을 수 있다.(고가의 장비다)  
  
요청이 들어오면 디스크 회전 방향을 고려하여 큐에 들어온 요청을 회전 방향에 맞추어 재정렬해 서비스 한다.

[그림10-33] p.503

```
Request: 5 -> 1 -> 9
Sort: 1 -> 5 -> 9
```

## 📌 <b>RAID(Redundant Array of Independent Disks)</b>
자동으로 백업하고 장애 발생시 복수하는 시스템으로 '레이드' 라고 부른다.  
RAID 의 원리는 값싼 디스크를 이용해서 하나의 원본 디스크와 같은 크기의 백업 디스크에 내용을 동시 저장하고, 고장시 다른 디스크를 사용해서
데이터를 복구하는 것이다.  
  
이러한 방식을 2개의 디스크에 거울처럼 똑같은 내용을 저장한다는 의미에서 미러링(Mirroring) 이다. (RAID1 은 순수한 미러링을 지원)  
또 데이터를 나누어 저장하고, 여러개의 디스크에 접근해서 작업해 입출력 속도를 높이는 방법을 스트라이핑(Striping) 이라고 한다.

### ⚙ <b>RAID 0 (Striping)</b>
병렬로 연결된 여러 개의 디스크에 데이터를 동시에 입출력할 수 있도록 구성된다.

[그림10-34] p.505

이론적으로 디스크 1개만 쓰는 방식보다 4개를 쓴다면 4배 빠르지만 RAID 0 의 경우에는 장애 발생 시 복구하는 기능이 없어 데이터를 잃는다.

### ⚙ <b>RAID 1 (Mirroring)</b>
하나의 데이터를 2개의 디스크에 나누어 저장하여 장애 시 백업 디스크로 활용한다.

[그림10-35] p.506

최소 2개 이상의 짝수 개의 디스크를 필요로 하는 특징이 있으며, 데이터 저장을 2번 하기 때문에 속도가 느려지고, 추가의 디스크가 필요로 하다는 것이다.

### ⚙ <b>RAID2</b>
오류 검출 기능이 추가되어 오류 교정 코드(Error Correcting Code, ECC) 가 추가 되었다.

[그림10-36] p.507

오류 교정 코드를 별도의 디스크에 보관하고 있다가 장애 발생 시 이를 이용하여 데이터를 복구한다.  
비트별로 디스크에 분산되어 저장되는데, 각 비트의 오류 교정 코드를 구성해서 비트 단위로 복구하기 때문이고, n개의 디스크에 대해 오류 교정 코드를 저장하기
위해서 n-1 개의 추가 디스크를 필요로 한다.

### ⚙ <b>RAID 3</b>
짝수, 홀수 패리티 비트를 통한 오류 복구 방식이 있는데, 간단하게 비트중 1을 갖는 비트의 갯수가 짝수인지 홀수인지 확인하고, 짝수 패리티 비트인데
짝수가 아니라면 손상된 디스크의 비트를 유추할 수 있는 방법이다.

[그림10-38] p.508

디스크는 섹터 단위로 읽기 때문에 섹터끼리 묶어서 오류를 검사하면 오류가 있는 섹터를 검출할 수 있고 이를 'N-way' 패리티 비트라고 부른다.  
하지만 섹터 단위로 계산하기 때문에 필요한 계산량이 많다.

### ⚙ <b>RAID 4</b>
데이터를 블록 단위로 관리한다.

[그림10-39] p.509

RAID 3 의 경우 모든 디스크의 섹터에 나누어 저장해 패리티 비트를 구성하는데 데이터를 읽거나 쓸 때 모든 디스크가 동작하기 떄문에 이를 보완해서
데이터를 하나의 디스크에 블록 단위로 저장하고, 패리티 비트를 블록과 연결하여 구성한다.

### ⚙ <b>RAID 5</b>
RAID 4 의 문제점은 모든 패리티 비트가 하나의 디스크에 저장되기 때문에 입출력이 일어날 때마다 패리티 비트 디스크에 데이터가 저장되어 병목 현상이 발생된다.  
또한 패리티 비트가 저장된 디스크와 다른 디스크에서 동시에 장애가 발생하면 복구가 안된다.

[그림10-40] p.510

패리티 비트를 여러 디스크에 분산하여 보관해 리스크를 분산하고, 병목 현상을 완화한다.  
또한 데이터를 저장하는 디스크와 패리티 비트가 보관되는 디스크를 다르게 보관한다.

### ⚙ <b>RAID 6</b>
RAID 5 와 같은 방식이지만 패리티 비트를 2개 저장한다.  
RAID 5 의 경우 디스크 장애가 2개 동시에 발생하면 복구가 불가능하기 때문에 이를 보완하기 위해서다.

[그림10-41] p.511

늘어난 패리티 비트에 계산량이 많고, 추가로 필요로 하는 디스크도 늘었다.

### ⚙ <b>RAID 10(1+0)</b>
하드디스크의 가격이 싸지면서 빠른 입출력을 갖는 RAID 0과 복구 기능을 갖는 RAID 1을 결합한 방법이다.

[그림10-42] p.512

0+1과 1+0 방법이 그림에 나타난다.  
차이점은 0+1은 장애 발생시 모든 디스크를 중단해야 하지만 1+0은 한쪽만 중단해도 복구할 수 있다.

### ⚙ <b>RAID 50(5+0), 60(6+0)</b>
0 으로 묶어서 성능 항샹을 노리지만 입출력 계산량이 늘어난다.

[그림10-43] p.513