# **Chapter07 - 물리 메모리 관리**

# **[ 📋 목차 ]**
- 메모리 관리의 개요
- 메모리 주소
- 단일 프로그래밍 환경에서의 메모리 할당
- 다중 프로그래밍 환경에서의 메모리 할당
- 컴피알과 메모리 관리

****

# **[ 🗂️ 정리 ]**︎
## 📌 메모리 관리의 개요

### ⚙ <b>메모리 관리의 복잡성</b>

- 메모리 주소 번지는 0부터 시작한다.
- 메모리 주소 레지스터(MAR) 를 사용해서 메모리에서 데이터를 가져오거나, 메모리에 적재
- 폰노이만 구조에서 메모리는 유일한 작업 공간이며, 모든 프로그램은 메모리에 올라와야 실행 가능

왜 복잡할까?  
👉 시분할 시스템에서 OS를 포함한 모든 프로그램이 메모리에 실행되기 떄문에 복잡하다.   
👉 복잡한 메모리 관리는 메모리 관리 시스템(Memory Management System, MMS) 가 담당한다.

### ⚙ <b>메모리 관리의 이중성</b>

이중성?  
👉 MMS 입장에서는 메모리를 효율적으로 사용하고 싶고, 프로세스 입장에서는 메모리를 혼자서 사용하고 싶다.

- 프로세스를 더 큰 공간으로 옮긴다 -> 빈 공간 처리
- 빈 공간이 여러개 생긴다 -> 합친다
  
위에서 나오는 메모리 공간을 작업하는 것은 실제로는 매우 복잡하다.

### ⚙ <b>소스코드의 번역과 실행</b>
1. <b>컴파일러(Compiler)와 인터프리터(Interpreter)</b>  

👉 0과 1로 되어있는 기계어는 인간이 이해하고 사용하기 어렵기 때문에 언어를 대신해서 사용하고, 기계어와 가장 유사한 언어인 어셈블리어가 있고
컴퓨터의 동작을 가장 직접적으로 표현한 언어로 <b>저급 언어(Low Level Language)</b>라고 한다.

반대의 개념은 <b>고급 언어(High Level Language)</b> 라고 부른다.  
이렇게 고급 언어로 작성된 코드를 컴퓨터가 실행할 수 있는 기계어로 번역하는 프로그램이 컴파일러와 인터프리터다.
  
- 컴파일러: 소스코드를 컴퓨터가 실행할 수 있는 기계어로 번역 후 한 번에 실행한다.
- 인터프리터: 소스코드를 한 라인씩 번역하여 실행한다.

### ⚙ <b>컴파일러의 목적</b>
- 오류 발견: 오류 검출 후 실행 시 문제가 없도록 하는 것이 목적이며 오류 검출을 위해서 심볼 테이블(Symbol Table)을 이용한다.
  선언부에 명시한 변수의 이름과 타입별로 모아놓은 테이블로 검사를 진행한다.
- 코드 최적화: 중복 사용을 합치거나, 사용하지 않는 변수를 제거 하면서 최적화를 진행한다.

### ⚙ <b>컴파일러와 인터피르터 차이</b>
'컴파일러' 는 코드가 실행되기 전에 소스코드를 점검하여 오류를 검출하고, 불필요한 부분을 정리하여 최적화된 파일을 만든다.  
'인터프리터' 는 한 줄씩 위에서 아래로 실행되기 때문에 반복하거나, 불필요한 부분을 확인할 수 없다.

### ⚙ <b>컴파일 과정</b>
```
소스코드 -> 목적 코드(Object Code) -> Library Linking - Execute
```

- 소스코드 작성 및 컴파일: 소스 코드가 컴파일되면 목적 코드가 된다.
- 목적 코드와 라이브러리 연결: 라이브러리 코드를 목적 코드에 삽입하여 최종 실행 파일을 만든다.
- 동적 라이브러리를 포함하여 최종 실행: 라이브러리 코드를 비워두고 실행 한 뒤 컴파일한 후에 실행 코드를 라이브러리에서 가져와서
실행하는 방법을 사용할 때 사용되는 라이브러리가 동적 라이브러리(Dynamic Library)라고 부르고, 윈도우에서 동적 라이브러리 파일을
Dynamic Link Loader, DLL 라고 부른다.

### ⚙ <b>메모리 관리자의 역할</b>
메모리 관리를 담당하는 관리 역할은 MMU(Memory Manage Unit, MMU) 가 담당하는데 메모리에 가져오기(Fetch), 배치(Placement),
재배치(Replacement) 작업을 수행한다.

- 가져오기: 프로세스와 데이터를 메모리로 가져오는 작업(모든 데이터가 아닌 일부만 가져올 수 있음 -> 스왑 디스크와 연관된 내용일듯)
  - 정책: 어느 시점에 메모리로 가져올까?
    - 프로세스 요청 시점
    - 예상되는 데이터 미리 가져오기(Prefetch)
- 배치: 프로세스와 데이터를 배치할 메모리 위치를 결정하는 작업으로 메모리를 어떻게 잘라서 사용할지에 따라서 메모리 관리 복잡성이 달라진다.(메모리 할당과
  다편화에 연관된 내용일듯)
  - 정책: 어떤 위치에 가져다 놓을까?
    - 페이징(Paging): 메모리를 같은 크기로 자르는 것
    - 세그먼테이션(Segmentation): 프로세스 크기에 맞춰서
- 재배치: 메모리가 가득 찼다면 메모리상에 있는 프로세스를 하드디스크로 옮겨야 새로운 프로세스가 동작 가능하기 때문에 오래된 프로세스를 내보내는 작업(스왑)
  - 정책: 교체 알고리즘(Replacement Algorithm) 사용

****

## 📌 메모리 주소

### ⚙ <b>32bit CPU 와 64bit CPU 차이</b>
CPU 의 비트는 한 번에 다룰 수 있는 데이터의 최대 크기를 의미한다.(32bit 는 32bit 를 최대로 한 번에 다룰 수 있다.)  

- 32bit CPU 내의 레지스터는 32bit 이다.
- 32bit CPU 의 산술 논리 연산장치도 32bit 처리를 할 수 있다.
- 버스들의 대역폭도 32bit 이다.
- 32bit CPU 가 표현 가능한 메모리 주소 번지는 0 ~ 2^32-1(00000000 ~ FFFFFFFF) 까지로 약 4GB 이다.

실제로 64bit CPU 가 표현 가능한 메모리 번지수는 16,777,216TB(18EB) 까지 가능하다.  
이렇게 나누어논 메모리 주소를 하드웨어 입장에서는 물리 주소 공간(Physical Address Space), 사용자 입장에서 논리 주소 공간(Logical Address Space) 라 한다.

```
2^10 -> 1KB
2^20 -> 1MB
2^30 -> 1GB
2^40 -> 1TB
2^50 -> 1PB
2^60 -> 1EB
```

### ⚙ <b>절대 주소와 상대 주소</b>
먼저 메모리 상에서 OS와 사용자 영역이 나뉘어서 OS 영역이 침범되지 않도록 분리되어 있다.  
OS 영역이 침범당하지 않게 하기 위해서 하드웨어 '경계 레지스터' 의 도움을 받는다.

- 절대 주소(Absolute Address): 컴파일 시점에는 메모리상에 올리지 않기 때문에 임의로 0번부터 배정하고 실제 프로세스가 실행되면서 메모리상에
올라갈 때 메모리 만큼의 주소를 더해서 계산한다.
  ```
  0번 주소로 배정하고 메모리상에 400번에 올라가게 되면 배정한 모든 메모리를 400 더해서 실제 하드웨어상의 주소로 변경한다.
  (실제 하드웨어 주소는 컴포터에 꽂혀있는 RAM의 실제 주소를 말한다.)
  ```
- 상대 주소(Relative Address): 사용자 입장에서 절대주소는 위험하다. 운영체제가 업데이터 되어 사용되는 메모리 용량이 커진다면? 실수 혹은 고의적으로
OS의 영역을 침범할 여지가 있기 때문이다. 그래서 절대 주소와는 다르게 매핑된 상대 주소를 사용한다.
  ```
  OS가 399번 까지 주소를 사용하고 있다면 상대 주소는 400을 다른 주소로 매핑해서 사용한다. ex) 400 -> 0 
  ```

### ⚙ <b>상대 주소를 절대 주소로 변환하는 과정</b>
상대 주소를 사용하면 실제로 접근하기 위해서는 물리 주소로 변환 해야한다.
  
> 책에는 가볍게 쓰여져 있지만 MMU 에 의해서 Page Table 참조해 물리 주소와 논리 주소를 변환하는 과정을 생략 했거나 
> 뒤에서 등장할 듯 (Page Fault 등)

****

## 📌 단일 프로그래밍 환경에서의 메모리 할당
### ⚙ <b>메모리 오버레이</b>
프로그램 크기가 실제 물리 메모리보다 클 때 전체 프로그램을 메모리에 가져오는 대신 적당한 크기로 잘라서 가져오는걸 메모리 오버레이(Memory Overlay) 라고 한다.  
기능이 필요할 때마다 해당 모듈을 메모리에 불러와서 실행하기 때문에 전체 프로세스를 한 번에 메모리에 올리는 것 보다는 느리지만 전체 프로세스가 메모리 보다 큰 용량을 갖고
있어도 실행할 수 있는 장점이 있다.

### ⚙ <b>스왑(Swap)</b>
위에서 설명한 메모리 오버레이가 일어나면서 메모리에 올렸던 모듈을 내리고 다른 모듈을 올린다고 하면 올려놓은 메모리는 어디로 보내야할까?  
👉 이 질문의 등장은 메모리에 올렸던 모듈의 기능을 또 사용할 수 있는데 하드 디스크가 아닌 별도의 공간에 보관한다.
  
메모리에서 쫓겨난 프로세스를 보관하는 공간을 스왑 영역(Swap Area) 라고 한다.  
메모리로 넣는 잡업은 Swap in, 메모리에서 내보내는 작업은 Swap out 이라고 한다.
  
스왑 영역은 저장 장치에 보관되지만 저장장치 관리자가 아닌 메모리 관리자에 의해서 관리된다.

> ※ window 컴퓨터 최대 절전 모드 실행시 CPU 와 메모리 전력 공급이 끊기기 때문에 실행중인 프로세스가 다 날아갸야 하는데
> 스왑 영역에 옮긴다. (하드 디스크 전원이 깜박이다가 꺼지는 이유)

****

## 📌 다중 프로그래밍 환경에서의 메모리 할당
### ⚙ <b>메모리 분할 방식</b>
- 가변 분할 방식(Variable-size Partitioning): 프로세스의 크기에 따라 메모리 분할
  - 크기에 맞추 주기 때문에 효율적인 이점이 있다.
  - 크기에 맞도록 준비가 필요하다. (극단적으로 크거나 작은 크기의 프로세스만 들어온다면)
- 고정 분할 방식(Fixed-size Partitioning): 프로세스와 무관하게 메모리 분할
  - 관리가 용이하다.
  - 지역성을 지켜줄 수 있지 않다. (같은 프로세스지만 메모리 상에서 연속적이지 않음)

### ⚙ <b>메모리 분할 방식의 구현</b>
'가변 분할 방식' 의 경우 프로세스 크기에 맞춰 메모리가 분할되기 때문에 연속된 공간에 배치되어 연속 메모리 할당(Contiguous Memory Allocation) 이라고 한다.

- 장점
  -  프로세스가 연속된 공간에 배치된다.
- 단점
  - 복잡한 메모리 관리: 프로세스를 할당하기에 메모리 공간이 충분히 있어도 할당하지 못하는 상황이 생기는데 이 공간을 하나로 합치는 작업과 다른 프로세스의 위치를 옮기는 작업이 필요하다.
    (외부 단편화를 말하는것 같음)
  
'고정 분할 방식' 의 경우 큰 프로세스를 여러 조각에 배치하여 메모리 위치 상에서 분산되어 배치되어 비연속 메모리 할당(Non-Contiguous Memory Allocation) 이라고 한다.

- 장점
  - 일정한 크기로 정해져있기 때문에 관리가 수월하다.
- 단점
  - 프로세스가 필요한 크기보다 더 많은 메모리가 할당되어 메모리 낭비가 발생한다.(내부 단편화를 말하는것 같음)

### ⚙ <b>가변 분할 방식의 메모리 관리</b>
세그먼테이션 기법으로도 불린다.

#### <b>1. 외부 단편화(External Fragmentation)</b>  
👉 프로세스가 요구하는 메모리 공간을 할당할 메모리 공간이 있지만 연속되있지 않기 때문에 할당을 하지 않는 문제가 발생하는데, 이를 해결하기 위해서 다른
프로세스에게 먼저 메모리 할당을 하면 아사 현상까지 일어날 수 있기 때문에 문제가 발생한다.
  
이렇게 작은 조각들로 나뉘어져 발생하는 현상을 단편화(Fragmentation) 또는 조각화라고 한다.  
외부 단편화를 해결하기 위해서 메모리 배치 방식(Memory Placement Strategy) 혹은 조각 모음(Defragmentation) 이라고 한다.  
'메모리 배치 방식은' 단편화가 나지 않도록 배치하는 선처리 방식이고, '조각 모음' 은 조각을 모아서 큰 조각으로 만드는 후처리 방식이다.

#### <b>2. 메모리 배치 방식</b>
- <b>최초 배치(First Fit)</b>
  - 단편화 고려 없이 적재 가능한 빈 공간에 프로세스를 배치하는 방법
- <b>최적 배치(Best Fit)</b>
  - 메모리 공간의 빈 공간을 전부 확인하여 적당한 크기 중 가장 가운데 프로세스를 배치하는 방법
- <b>최악 배치(Worst Fit)</b>
  - 빈 공간을 전부 확인 후 가장 큰 공간에 프로세스를 배치하는 방법
- <b>버디 시스템(Buddy System)</b>

> 나는 First, Next, Best Fit 으로 배웠는데... Worst 는 처음 보네..

#### <b>3. 조각 모음</b>
어떤 메모리 배치 방식을 사용해도 단편화를 발생 시킨다.  
가변 분할 방식의 목적은 메모리 사용 효율성을 높이는 것인데 근본적인 문제를 해결하지 못한다.
  
작은 프로세스가 메모리 사용을 끝나고 반환 한다면, 작은 조각이 남을텐데 작은 그대로 두면 단편화될 확률이 높아서 더 큰 메모리로 합쳐야 하는데
이걸 조각 모음이라고 한다.

```
조각 모음 순서
1. 이동할 프로세스의 동작을 멈춘다.
2. 프로세스의 상대 주소값을 바꾼다.
3. 프로세스 재시작한다.

위 과정 후 메모리를 합치는 작업을 한다. (복잡한 이유)
```

### ⚙ <b>고정 분할 방식의 메모리 관리</b>
고정 분할의 문제는 프로세스가 메모리의 여러 조각으로 나뉘어 저장되는 것이다.

#### <b>프로세스 배치와 내부 단편화</b>
프로세스가 메모리에 연속적일 필요가 없기 때문에 공간적으로 효율적인 장점이 있지만 메모리보다 작은 프로세스가 배치되어 낭비되는 공간이 생긴다.  
위와 같은 문제점을 내부 단편화(Internal Fragmentation) 이라고 한다.

|구분|가변 분할 방식|고정 분할 방식|
|:---:|:---:|:---:|
|메모리 단위|세그먼테이션|페이징|
|특징|연속 메모리|비연속 메모리|
|장점|프로세스가 한 덩어리|메모리 관리가 용이|
|단점|빈 공간 관리|프로세스 분할 처리|
|단편화|외부 단편화|내부 단편화|

### ⚙ <b>버디 시스템</b>
가변 분할의 단점을 완화하기 위해서 고안된 방법

#### <b>버디 시스템의 작동 방식</b>
가변과 고정 분할 방식의 중간 구조

1. 프로세스 크기에 맞춰 1/2 로 분할해 메모리에 배치
2. 나뉜 각 메모리에는 1개의 프로세스가 들어간다.
3. 프로세스가 종료되면 빈 조각과 합쳐서 하나의 큰 덩어리를 만든다.

> 쉽게 큰 메모리를 최소로 적합하도록 분할해서 할당한다.

ex) Total: 16KB
 
|구분|Case1|Case2|
|:---:|:---:|:---:|
|요구|4KB|3KB|
|할당|4KB|4KB|

프로세스가 메모리 반환 하면 메모리상에 앞, 뒤 메모리 할당 여부 확인 후 큰 메모리로 만드는 방식이다.  
여전히 내부 단편화가 발생하는 시스템 이지만 가변 분할 방식보다 효과적으로 공간을 관리할 수 있는 이유는 덩어리가 모여 있어서 통합하기가
용이하다.
  
고정 분할 방식이 메모리를 관리하는 면에서는 간편하다.

****

## 📌 컴피일과 메모리 관리

### ⚙ <b>컴파일 과정</b>

[그림 7-39] p.367

- 분할 컴파일: 여러 사람이 소스코드를 한 번에 합쳐서 컴파일 하면 오류 검출시 번거롭기 때문에 각자의 목적 코드 합쳐서 컴파일 하는 방법이다.

### ⚙ <b>변수와 메모리 할당</b>
컴파일과 메모리 할당은 밀접한 관계를 갖는다.

```
char str='a';
int vol=7;
float pri=2.3;
```

위 코드가 메모리에 적재될 때 메모리 시작 번지가 0부터라면

- 0: char(1 Byte)
- 1 ~ 4: int(4 Bytes)
- 5 ~ 12: float(8 Bytes)

위처럼 이진수 형태로 메모리에 적재된다.  
또 메모리 확보 뿐 아니라 오류를 찾기 위해 심볼 테이블도 유지한다.

|심볼|종류|범위|주소|
|:---:|:---:|:---:|:---:|
|str|char|main()|0|
|vol|int|main()|1|
|pri|float|main()|5|

범위는 영역을 나타내는 scope 이다.  

변수 ex) int 라는건 사실 컴퓨터 입장에서는 필요 없는 정보이지만 프로그래머가 주소를 기억하고 코드를 짤 수 없기 때문에 필요한 정보다.  
그런 이유로 변수는 메모리 주소의 또 다른 이름이다.
